{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ckiptagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ziZDZAu2jxY1",
    "outputId": "71765382-04ed-47b7-a6db-2a0df41136a9"
   },
   "outputs": [],
   "source": [
    "# from ckiptagger import data_utils\n",
    "# data_utils.download_data_gdown(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tbl_post = pd.read_csv('tbl_post.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tbl_post)):\n",
    "    temp = tbl_post['Content'][i].replace(\"['\", '').replace(\"']\",'')\n",
    "    tbl_post['Content'][i] = temp\n",
    "tbl_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNeebE6fERfv"
   },
   "outputs": [],
   "source": [
    "# 切詞用\n",
    "def strQ2B(ustring):\n",
    "    \"\"\"把字串全形轉半形\"\"\"\n",
    "    ss = []\n",
    "    for s in ustring:\n",
    "        rstring = \"\"\n",
    "        for uchar in s:\n",
    "            inside_code = ord(uchar)\n",
    "            if inside_code == 12288:  # 全形空格直接轉換\n",
    "                inside_code = 32\n",
    "            elif (inside_code >= 65281 and inside_code <= 65374):  # 全形字元（除空格）根據關係轉化\n",
    "                inside_code -= 65248\n",
    "            rstring += chr(inside_code)\n",
    "        ss.append(rstring)\n",
    "    return ''.join(ss)\n",
    "\n",
    "# 停用詞\n",
    "# with open('stopwords_tc.txt', encoding='utf-8', mode='r') as f:\n",
    "#     stop_words = []\n",
    "#     for l in f:\n",
    "#         stop_words.append(l.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------工作區----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切詞\n",
    "from ckiptagger import WS, POS, NER\n",
    "import pandas as pd\n",
    "# max(tbl_post['product_id'].unique())==1067-product_id最大\n",
    "max_product_id = max(tbl_post['product_id'].unique())\n",
    "\n",
    "ws = WS(\"./data\")\n",
    "pos = POS(\"./data\")\n",
    "Content_cut = []\n",
    "Positive_cut = []\n",
    "\n",
    "for i in range(max_product_id+1):\n",
    "    # 同產品->product\n",
    "    product1 = tbl_post[tbl_post['product_id']==i]\n",
    "    product = product1.reset_index(drop=True)\n",
    "    per_word_cut = []\n",
    "    per_pos_cut = []\n",
    "    \n",
    "    for j in range(len(product)):\n",
    "        ws_results = ws([product['Content'][j]])\n",
    "        pos_results = pos(ws_results)\n",
    "        \n",
    "        for word in ws_results[0]:\n",
    "            word = strQ2B(word)\n",
    "            per_word_cut.append(word)\n",
    "            \n",
    "        for pos_word in pos_results[0]:\n",
    "            per_pos_cut.append(pos_word)\n",
    "                    \n",
    "    Content_cut.append([per_word_cut])\n",
    "    print(Content_cut)\n",
    "    Positive_cut.append(per_pos_cut)\n",
    "    print(Positive_cut)\n",
    "    \n",
    "Content_cutting = pd.DataFrame(Content_cut)\n",
    "Positive_cutting = pd.DataFrame(Positive_cut)\n",
    "Content_cutting['part of speech'] = Positive_cut\n",
    "Content_cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理\n",
    "product_id_Index=[]\n",
    "max_product_id = max(tbl_post['product_id'].unique())\n",
    "for i in range(max_product_id):\n",
    "    i = i+1\n",
    "    product_id_Index.append(i)\n",
    "product_id_Index = pd.DataFrame(product_id_Index)\n",
    "product_id_Index['content_cut'] = Content_cutting[0]\n",
    "product_id_Index['part of speech'] = Content_cutting['part of speech']\n",
    "product_id_Index.rename(columns = {0:'product_id'}, inplace = True)\n",
    "product_id_Index\n",
    "# 將該id沒有爬蟲內容者過濾\n",
    "product_id_Index_final = product_id_Index[product_id_Index.content_cut.str.len()>0].reset_index(drop=True)\n",
    "product_id_Index_final\n",
    "product_id_Index_final.to_csv('Content_cut.csv', index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ckip_test_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
