{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('../../graduation_project_outfiles/tmunlp_1.6B_WB_300dim_2020v1.bin.gz', \n",
    "                                                        unicode_errors='ignore', \n",
    "                                                        binary=True)\n",
    "# 'y_360W_cbow_2D_300dim_2020v1.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_content = pd.read_csv('../training_data/Content_cut.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from product1 to 1067 -> create content_pos_list\n",
    "for i in range(0, len(raw_content)+1):\n",
    "    raw_content_list = []\n",
    "    for index, row in raw_content.iterrows():\n",
    "        if(index==i):\n",
    "            temp_list = row['content_cut']\n",
    "            raw_content_list.extend(eval(temp_list))\n",
    "\n",
    "    raw_pos_list = []\n",
    "    for index, row in raw_content.iterrows():\n",
    "        if(index==i):\n",
    "            temp_pos_list = row['part of speech']\n",
    "            raw_pos_list.extend(eval(temp_pos_list))\n",
    "    \n",
    "    locals()['content_pos_list_'+str(i)] = pd.DataFrame(data = raw_content_list, columns=['Content'])\n",
    "    pos_list = pd.DataFrame(data = raw_pos_list, columns=['PoS'])\n",
    "    locals()['content_pos_list_'+str(i)]['PoS'] = pos_list['PoS']\n",
    "    locals()['content_pos_list_'+str(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_similarity_(+product_id)->不同產品的相似度\n",
    "# word_similarity/battery/word_similarity_battery_\n",
    "for j in range(len(raw_content)):\n",
    "    temp = locals()['content_pos_list_'+str(j)]\n",
    "    score_list = []\n",
    "    for i in range(len(temp)):\n",
    "        try:\n",
    "            if temp['PoS'][i] in ['A']:\n",
    "                score = model.similarity('電池', temp['Content'][i])\n",
    "                score_list.append([score, temp['Content'][i], temp['PoS'][i]])\n",
    "        except:\n",
    "            continue\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = pd.DataFrame(data = score_list, columns=['Score', 'Word', 'PoS'])\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].drop_duplicates(subset=['Score', 'Word', 'PoS'], keep=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].sort_values(by=['Score'], ascending=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])].to_csv(\"word_similarity/battery/word_similarity_battery_\"+str(raw_content['product_id'][j]) +\".csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_similarity_(+product_id)->不同產品的相似度\n",
    "# word_similarity/budget/word_similarity_budget_\n",
    "for j in range(len(raw_content)):\n",
    "    temp = locals()['content_pos_list_'+str(j)]\n",
    "    score_list = []\n",
    "    for i in range(len(temp)):\n",
    "        try:\n",
    "            if temp['PoS'][i] in ['A']:\n",
    "                score = model.similarity('預算', temp['Content'][i])\n",
    "                score_list.append([score, temp['Content'][i]])\n",
    "        except:\n",
    "            continue\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = pd.DataFrame(data = score_list, columns=['Score', 'Word'])\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].drop_duplicates(subset=['Score', 'Word'], keep=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].sort_values(by=['Score'], ascending=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])].to_csv(\"word_similarity/budget/word_similarity_budget_\"+str(raw_content['product_id'][j]) +\".csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_similarity_(+product_id)->不同產品的相似度\n",
    "# word_similarity/budget/word_similarity_chip_\n",
    "for j in range(len(raw_content)):\n",
    "    temp = locals()['content_pos_list_'+str(j)]\n",
    "    score_list = []\n",
    "    for i in range(len(temp)):\n",
    "        try:\n",
    "            if temp['PoS'][i] in ['A']:\n",
    "                score = model.similarity('晶片', temp['Content'][i])\n",
    "                score_list.append([score, temp['Content'][i]])\n",
    "        except:\n",
    "            continue\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = pd.DataFrame(data = score_list, columns=['Score', 'Word'])\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].drop_duplicates(subset=['Score', 'Word'], keep=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].sort_values(by=['Score'], ascending=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])].to_csv(\"word_similarity/chip/word_similarity_chip_\"+str(raw_content['product_id'][j]) +\".csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_similarity_(+product_id)->不同產品的相似度\n",
    "# word_similarity/budget/word_similarity_screen_\n",
    "for j in range(len(raw_content)):\n",
    "    temp = locals()['content_pos_list_'+str(j)]\n",
    "    score_list = []\n",
    "    for i in range(len(temp)):\n",
    "        try:\n",
    "            if temp['PoS'][i] in ['A']:\n",
    "                score = model.similarity('螢幕', temp['Content'][i])\n",
    "                score_list.append([score, temp['Content'][i]])\n",
    "        except:\n",
    "            continue\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = pd.DataFrame(data = score_list, columns=['Score', 'Word'])\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].drop_duplicates(subset=['Score', 'Word'], keep=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].sort_values(by=['Score'], ascending=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])].to_csv(\"word_similarity/screen/word_similarity_screen_\"+str(raw_content['product_id'][j]) +\".csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_similarity_(+product_id)->不同產品的相似度\n",
    "# word_similarity/budget/word_similarity_lens_\n",
    "for j in range(len(raw_content)):\n",
    "    temp = locals()['content_pos_list_'+str(j)]\n",
    "    score_list = []\n",
    "    for i in range(len(temp)):\n",
    "        try:\n",
    "            if temp['PoS'][i] in ['A']:\n",
    "                score = model.similarity('鏡頭', temp['Content'][i])\n",
    "                score_list.append([score, temp['Content'][i]])\n",
    "        except:\n",
    "            continue\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = pd.DataFrame(data = score_list, columns=['Score', 'Word'])\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].drop_duplicates(subset=['Score', 'Word'], keep=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].sort_values(by=['Score'], ascending=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])].to_csv(\"word_similarity/lens/word_similarity_lens_\"+str(raw_content['product_id'][j]) +\".csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_similarity_(+product_id)->不同產品的相似度\n",
    "# word_similarity/budget/word_similarity_capacity_\n",
    "for j in range(len(raw_content)):\n",
    "    temp = locals()['content_pos_list_'+str(j)]\n",
    "    score_list = []\n",
    "    for i in range(len(temp)):\n",
    "        try:\n",
    "            if temp['PoS'][i] in ['A']:\n",
    "                score = model.similarity('容量', temp['Content'][i])\n",
    "                score_list.append([score, temp['Content'][i]])\n",
    "        except:\n",
    "            continue\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = pd.DataFrame(data = score_list, columns=['Score', 'Word'])\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].drop_duplicates(subset=['Score', 'Word'], keep=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])] = locals()['word_similarity_'+str(raw_content['product_id'][j])].sort_values(by=['Score'], ascending=False)\n",
    "    locals()['word_similarity_'+str(raw_content['product_id'][j])].to_csv(\"word_similarity/capacity/word_similarity_capacity_\"+str(raw_content['product_id'][j]) +\".csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Word</th>\n",
       "      <th>PoS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6362</th>\n",
       "      <td>0.481510</td>\n",
       "      <td>幅度</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15769</th>\n",
       "      <td>0.465828</td>\n",
       "      <td>記憶卡</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.427755</td>\n",
       "      <td>mAh</td>\n",
       "      <td>FW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13021</th>\n",
       "      <td>0.397428</td>\n",
       "      <td>音量</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13640</th>\n",
       "      <td>0.393748</td>\n",
       "      <td>厚度</td>\n",
       "      <td>Na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>-0.196737</td>\n",
       "      <td>去</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315</th>\n",
       "      <td>-0.201134</td>\n",
       "      <td>趁著</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>-0.203130</td>\n",
       "      <td>尋找</td>\n",
       "      <td>VC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10628</th>\n",
       "      <td>-0.205138</td>\n",
       "      <td>黑掉</td>\n",
       "      <td>VH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26186</th>\n",
       "      <td>-0.205455</td>\n",
       "      <td>退後</td>\n",
       "      <td>VA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2152 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Score Word PoS\n",
       "6362   0.481510   幅度  Na\n",
       "15769  0.465828  記憶卡  Na\n",
       "1635   0.427755  mAh  FW\n",
       "13021  0.397428   音量  Na\n",
       "13640  0.393748   厚度  Na\n",
       "...         ...  ...  ..\n",
       "21109 -0.196737    去   T\n",
       "6315  -0.201134   趁著   P\n",
       "3387  -0.203130   尋找  VC\n",
       "10628 -0.205138   黑掉  VH\n",
       "26186 -0.205455   退後  VA\n",
       "\n",
       "[2152 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # single test\n",
    "# score_list = []\n",
    "# for i in range(len(content_pos_list_0)):\n",
    "#     try:\n",
    "#         if content_pos_list_0['PoS'][i] in ['A']:\n",
    "#             score = model.similarity('容量', content_pos_list_0['Content'][i])\n",
    "#             score_list.append([score, content_pos_list_0['Content'][i], content_pos_list_0['PoS'][i]])\n",
    "#     except:\n",
    "#         continue\n",
    "# aa= pd.DataFrame(data = score_list, columns=['Score', 'Word', 'PoS'])   \n",
    "# aa=aa.drop_duplicates(subset=['Score', 'Word', 'PoS'], keep=False)\n",
    "# aa=aa.sort_values(by=['Score'], ascending=False)\n",
    "# aa\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
